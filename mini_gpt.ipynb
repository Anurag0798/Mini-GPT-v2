{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7c53d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0467be",
   "metadata": {},
   "source": [
    "### Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74268e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data.txt\", 'r', encoding='utf-8') as f:\n",
    "    text_data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e4b6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6608cc",
   "metadata": {},
   "source": [
    "### Converting to numerical embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7a6004",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=5000, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts([text_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24d9cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce356826",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = tokenizer.texts_to_sequences([text_data])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59e3c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2bfd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ae0119",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tokenizer.pkl\", 'wb') as f:\n",
    "    pickle.dump(tokenizer, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdf5226",
   "metadata": {},
   "source": [
    "### Creating X and y data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7ce74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 100\n",
    "\n",
    "def create_dataset(seq, window_size=max_seq_length):\n",
    "    input, labels = [], []\n",
    "    \n",
    "    for i in range(len(seq) - window_size):\n",
    "        input.append(seq[i: i+window_size])\n",
    "        labels.append(seq[i+1: i+window_size+1])\n",
    "    \n",
    "    return np.array(input), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1ae2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data, y_data = create_dataset(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8bb814",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ceea2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4421c5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e295af",
   "metadata": {},
   "source": [
    "### Creating positional encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071c291f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(layers.Layer):\n",
    "    def __init__(self, max_len, d_model):\n",
    "        super().__init__()\n",
    "        pos = np.arange(max_len)[:, np.newaxis]\n",
    "        i = np.arange(d_model)[np.newaxis, :]\n",
    "        angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "        angle_rads = pos * angle_rates\n",
    "        angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "        angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "        self.pos_encoding = tf.cast(angle_rads[np.newaxis, ...], dtype=tf.float32)\n",
    "\n",
    "    def call(self, x):\n",
    "        return x + self.pos_encoding[:, :tf.shape(x)[1], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8845f7d3",
   "metadata": {},
   "source": [
    "### Creating one Transformer block (referencing `Attention is all you need` paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84415f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_block(embed_dim, num_heads, ff_dim, dropout=0.1):\n",
    "    inputs = layers.Input(shape=(None, embed_dim))\n",
    "    attn_output = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)(inputs, inputs)\n",
    "    attn_output = layers.Dropout(dropout)(attn_output)\n",
    "    out1 = layers.LayerNormalization(epsilon=1e-6)(inputs + attn_output)\n",
    "\n",
    "    ffn = tf.keras.Sequential([\n",
    "        layers.Dense(ff_dim, activation='relu'),\n",
    "        layers.Dense(embed_dim),\n",
    "    ])\n",
    "\n",
    "    ffn_output = ffn(out1)\n",
    "    ffn_output = layers.Dropout(dropout)(ffn_output)\n",
    "    out2 = layers.LayerNormalization(epsilon=1e-6)(out1 + ffn_output)\n",
    "    \n",
    "    return tf.keras.Model(inputs=inputs, outputs=out2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e967e89d",
   "metadata": {},
   "source": [
    "### Creating the MiniGPT architecture by stacking multiple transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2debc800",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 5000\n",
    "max_seq_len = 100\n",
    "embed_dim = 256\n",
    "num_heads = 8\n",
    "ff_dim = 1024\n",
    "num_layers = 96\n",
    "batch_size = 32\n",
    "epoch  = 10\n",
    "\n",
    "def build_gpt_model():\n",
    "    inputs = layers.Input(shape=(max_seq_len,))\n",
    "    x = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)(inputs)\n",
    "    x = PositionalEncoding(max_seq_len, embed_dim)(x)\n",
    "\n",
    "    for _ in range(num_layers):\n",
    "        x = transformer_block(embed_dim, num_heads, ff_dim)(x)\n",
    "\n",
    "    outputs = layers.Dense(vocab_size, activation='softmax')(x)\n",
    "    return tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c9fc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_gpt_model()\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4346e2de",
   "metadata": {},
   "source": [
    "### Training the MiniGPT on custom data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfecb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_data, y_data, batch_size=batch_size, epochs=epoch, validation_split=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1322c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('gpt_test_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7adf8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea82600",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8bd22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pickle\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "# Load trained model\n",
    "model = tf.keras.models.load_model(\"gpt_test_model.h5\", custom_objects={\"PositionalEncoding\": PositionalEncoding})\n",
    "\n",
    "# Load tokenizer\n",
    "with open(\"tokenizer.pkl\", \"rb\") as f:\n",
    "    tokenizer = pickle.load(f)\n",
    "\n",
    "# Parameters\n",
    "max_seq_len = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99da9c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(seed_text, model, tokenizer, num_tokens=50, temperature=1.0):\n",
    "    for _ in range(num_tokens):\n",
    "        token_seq = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_seq = token_seq[-max_seq_len:]  # Trim to max length\n",
    "        padded_seq = pad_sequences([token_seq], maxlen=max_seq_len)\n",
    "\n",
    "        preds = model.predict(padded_seq, verbose=0)[0, -1]  # Get prediction for last time step\n",
    "        preds = np.asarray(preds).astype('float64')\n",
    "\n",
    "        # Apply temperature sampling\n",
    "        preds = np.log(preds + 1e-9) / temperature\n",
    "        preds = np.exp(preds) / np.sum(np.exp(preds))\n",
    "\n",
    "        next_token_id = np.random.choice(len(preds), p=preds)\n",
    "        next_word = tokenizer.index_word.get(next_token_id, '')\n",
    "\n",
    "        seed_text += ' ' + next_word\n",
    "\n",
    "        if next_word == '':  # Optional: break if OOV or unknown word\n",
    "            break\n",
    "\n",
    "    return seed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3059687",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_text = \"who is sudhanshu\"\n",
    "generated = generate_text(seed_text, model, tokenizer, num_tokens=50, temperature=1.0)\n",
    "\n",
    "print(\"üìù Generated Text:\")\n",
    "print(generated)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
